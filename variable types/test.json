[
  {
    "patch_model": "Add",
    "change_type": "Assignment",
    "line_new": 287,
    "critical_vars": [
      "sma"
    ],
    "function": "*sem_obtain_lock",
    "filename": "linux/CVE-2013-4483/CVE-2013-4483_CWE-189_6062a8dc0517bce23e3c2f7d2fea5e22411269a3_sem.c.diff",
    "label": "True",
    "function_code": "static inline struct sem_array *sem_obtain_lock(struct ipc_namespace *ns,\n\t\t\tint id, struct sembuf *sops, int nsops, int *locknum)\n{\n\tstruct kern_ipc_perm *ipcp;\n\tstruct sem_array *sma;\n\n\trcu_read_lock();\n\tipcp = ipc_obtain_object(&sem_ids(ns), id);\n\tif (IS_ERR(ipcp)) {\n\t\tsma = ERR_CAST(ipcp);\n\t\tgoto err;\n\t}\n\n\tsma = container_of(ipcp, struct sem_array, sem_perm);\n\t*locknum = sem_lock(sma, sops, nsops);\n\n\t/* ipc_rmid() may have already freed the ID while sem_lock\n\t * was spinning: verify that the structure is still valid\n\t */\n\tif (!ipcp->deleted)\n\t\treturn container_of(ipcp, struct sem_array, sem_perm);\n\n\tsem_unlock(sma, *locknum);\n\tsma = ERR_PTR(-EINVAL);\nerr:\n\trcu_read_unlock();\n\treturn sma;\n}",
    "variable_definitions": {
      "sma": "struct sem_array *sma;"
    },
    "variable_types": {
      "sma": "struct pointer"
    },
    "type_mapping": {
      "sma": "struct pointer"
    },
    "CVE_description": "The ipc_rcu_putref function in ipc/util.c in the Linux kernel before 3.10 does not properly manage a reference count, which allows local users to cause a denial of service (memory consumption or system crash) via a crafted application.",
    "diff": "@@ -94,6 +94,7 @@\n struct sem {\n \tint\tsemval;\t\t/* current value */\n \tint\tsempid;\t\t/* pid of last operation */\n+\tspinlock_t\tlock;\t/* spinlock for fine-grained semtimedop */\n \tstruct list_head sem_pending; /* pending single-sop operations */\n };\n \n@@ -137,7 +138,6 @@ struct sem_undo_list {\n \n #define sem_ids(ns)\t((ns)->ids[IPC_SEM_IDS])\n \n-#define sem_unlock(sma)\t\tipc_unlock(&(sma)->sem_perm)\n #define sem_checkid(sma, semid)\tipc_checkid(&sma->sem_perm, semid)\n \n static int newary(struct ipc_namespace *, struct ipc_params *);\n@@ -189,11 +189,90 @@ void __init sem_init (void)\n \t\t\t\tIPC_SEM_IDS, sysvipc_sem_proc_show);\n }\n \n+/*\n+ * If the request contains only one semaphore operation, and there are\n+ * no complex transactions pending, lock only the semaphore involved.\n+ * Otherwise, lock the entire semaphore array, since we either have\n+ * multiple semaphores in our own semops, or we need to look at\n+ * semaphores from other pending complex operations.\n+ *\n+ * Carefully guard against sma->complex_count changing between zero\n+ * and non-zero while we are spinning for the lock. The value of\n+ * sma->complex_count cannot change while we are holding the lock,\n+ * so sem_unlock should be fine.\n+ *\n+ * The global lock path checks that all the local locks have been released,\n+ * checking each local lock once. This means that the local lock paths\n+ * cannot start their critical sections while the global lock is held.\n+ */\n+static inline int sem_lock(struct sem_array *sma, struct sembuf *sops,\n+\t\t\t      int nsops)\n+{\n+\tint locknum;\n+ again:\n+\tif (nsops == 1 && !sma->complex_count) {\n+\t\tstruct sem *sem = sma->sem_base + sops->sem_num;\n+\n+\t\t/* Lock just the semaphore we are interested in. */\n+\t\tspin_lock(&sem->lock);\n+\n+\t\t/*\n+\t\t * If sma->complex_count was set while we were spinning,\n+\t\t * we may need to look at things we did not lock here.\n+\t\t */\n+\t\tif (unlikely(sma->complex_count)) {\n+\t\t\tspin_unlock(&sem->lock);\n+\t\t\tgoto lock_array;\n+\t\t}\n+\n+\t\t/*\n+\t\t * Another process is holding the global lock on the\n+\t\t * sem_array; we cannot enter our critical section,\n+\t\t * but have to wait for the global lock to be released.\n+\t\t */\n+\t\tif (unlikely(spin_is_locked(&sma->sem_perm.lock))) {\n+\t\t\tspin_unlock(&sem->lock);\n+\t\t\tspin_unlock_wait(&sma->sem_perm.lock);\n+\t\t\tgoto again;\n+\t\t}\n+\n+\t\tlocknum = sops->sem_num;\n+\t} else {\n+\t\tint i;\n+\t\t/*\n+\t\t * Lock the semaphore array, and wait for all of the\n+\t\t * individual semaphore locks to go away.  The code\n+\t\t * above ensures no new single-lock holders will enter\n+\t\t * their critical section while the array lock is held.\n+\t\t */\n+ lock_array:\n+\t\tspin_lock(&sma->sem_perm.lock);\n+\t\tfor (i = 0; i < sma->sem_nsems; i++) {\n+\t\t\tstruct sem *sem = sma->sem_base + i;\n+\t\t\tspin_unlock_wait(&sem->lock);\n+\t\t}\n+\t\tlocknum = -1;\n+\t}\n+\treturn locknum;\n+}\n+\n+static inline void sem_unlock(struct sem_array *sma, int locknum)\n+{\n+\tif (locknum == -1) {\n+\t\tspin_unlock(&sma->sem_perm.lock);\n+\t} else {\n+\t\tstruct sem *sem = sma->sem_base + locknum;\n+\t\tspin_unlock(&sem->lock);\n+\t}\n+\trcu_read_unlock();\n+}\n+\n /*\n  * sem_lock_(check_) routines are called in the paths where the rw_mutex\n  * is not held.\n  */\n-static inline struct sem_array *sem_obtain_lock(struct ipc_namespace *ns, int id)\n+static inline struct sem_array *sem_obtain_lock(struct ipc_namespace *ns,\n+\t\t\tint id, struct sembuf *sops, int nsops, int *locknum)\n {\n \tstruct kern_ipc_perm *ipcp;\n \tstruct sem_array *sma;\n@@ -205,7 +284,8 @@ static inline struct sem_array *sem_obtain_lock(struct ipc_namespace *ns, int id\n \t\tgoto err;\n \t}\n \n-\tspin_lock(&ipcp->lock);\n+\tsma = container_of(ipcp, struct sem_array, sem_perm);\n+\t*locknum = sem_lock(sma, sops, nsops);\n \n \t/* ipc_rmid() may have already freed the ID while sem_lock\n \t * was spinning: verify that the structure is still valid\n@@ -213,7 +293,7 @@ static inline struct sem_array *sem_obtain_lock(struct ipc_namespace *ns, int id\n \tif (!ipcp->deleted)\n \t\treturn container_of(ipcp, struct sem_array, sem_perm);\n \n-\tspin_unlock(&ipcp->lock);\n+\tsem_unlock(sma, *locknum);\n \tsma = ERR_PTR(-EINVAL);\n err:\n \trcu_read_unlock();\n@@ -230,17 +310,6 @@ static inline struct sem_array *sem_obtain_object(struct ipc_namespace *ns, int\n \treturn container_of(ipcp, struct sem_array, sem_perm);\n }\n \n-static inline struct sem_array *sem_lock_check(struct ipc_namespace *ns,\n-\t\t\t\t\t\tint id)\n-{\n-\tstruct kern_ipc_perm *ipcp = ipc_lock_check(&sem_ids(ns), id);\n-\n-\tif (IS_ERR(ipcp))\n-\t\treturn ERR_CAST(ipcp);\n-\n-\treturn container_of(ipcp, struct sem_array, sem_perm);\n-}\n-\n static inline struct sem_array *sem_obtain_object_check(struct ipc_namespace *ns,\n \t\t\t\t\t\t\tint id)\n {\n@@ -254,21 +323,21 @@ static inline struct sem_array *sem_obtain_object_check(struct ipc_namespace *ns\n \n static inline void sem_lock_and_putref(struct sem_array *sma)\n {\n-\tipc_lock_by_ptr(&sma->sem_perm);\n+\trcu_read_lock();\n+\tsem_lock(sma, NULL, -1);\n \tipc_rcu_putref(sma);\n }\n \n static inline void sem_getref_and_unlock(struct sem_array *sma)\n {\n-\tipc_rcu_getref(sma);\n-\tipc_unlock(&(sma)->sem_perm);\n+\tWARN_ON_ONCE(!ipc_rcu_getref(sma));\n+\tsem_unlock(sma, -1);\n }\n \n static inline void sem_putref(struct sem_array *sma)\n {\n-\tipc_lock_by_ptr(&sma->sem_perm);\n-\tipc_rcu_putref(sma);\n-\tipc_unlock(&(sma)->sem_perm);\n+\tsem_lock_and_putref(sma);\n+\tsem_unlock(sma, -1);\n }\n \n /*\n@@ -276,9 +345,9 @@ static inline void sem_putref(struct sem_array *sma)\n  */\n static inline void sem_getref(struct sem_array *sma)\n {\n-\tspin_lock(&(sma)->sem_perm.lock);\n-\tipc_rcu_getref(sma);\n-\tipc_unlock(&(sma)->sem_perm);\n+\tsem_lock(sma, NULL, -1);\n+\tWARN_ON_ONCE(!ipc_rcu_getref(sma));\n+\tsem_unlock(sma, -1);\n }\n \n static inline void sem_rmid(struct ipc_namespace *ns, struct sem_array *s)\n@@ -371,15 +440,17 @@ static int newary(struct ipc_namespace *ns, struct ipc_params *params)\n \n \tsma->sem_base = (struct sem *) &sma[1];\n \n-\tfor (i = 0; i < nsems; i++)\n+\tfor (i = 0; i < nsems; i++) {\n \t\tINIT_LIST_HEAD(&sma->sem_base[i].sem_pending);\n+\t\tspin_lock_init(&sma->sem_base[i].lock);\n+\t}\n \n \tsma->complex_count = 0;\n \tINIT_LIST_HEAD(&sma->sem_pending);\n \tINIT_LIST_HEAD(&sma->list_id);\n \tsma->sem_nsems = nsems;\n \tsma->sem_ctime = get_seconds();\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, -1);\n \n \treturn sma->sem_perm.id;\n }\n@@ -818,7 +889,7 @@ static void freeary(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)\n \n \t/* Remove the semaphore set from the IDR */\n \tsem_rmid(ns, sma);\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, -1);\n \n \twake_up_sem_queue_do(&tasks);\n \tns->used_sems -= sma->sem_nsems;\n@@ -947,7 +1018,6 @@ static int semctl_setval(struct ipc_namespace *ns, int semid, int semnum,\n \tstruct sem_array *sma;\n \tstruct sem* curr;\n \tint err;\n-\tint nsems;\n \tstruct list_head tasks;\n \tint val;\n #if defined(CONFIG_64BIT) && defined(__BIG_ENDIAN)\n@@ -958,31 +1028,39 @@ static int semctl_setval(struct ipc_namespace *ns, int semid, int semnum,\n \tval = arg;\n #endif\n \n-\tsma = sem_lock_check(ns, semid);\n-\tif (IS_ERR(sma))\n-\t\treturn PTR_ERR(sma);\n+\tif (val > SEMVMX || val < 0)\n+\t\treturn -ERANGE;\n \n \tINIT_LIST_HEAD(&tasks);\n-\tnsems = sma->sem_nsems;\n \n-\terr = -EACCES;\n-\tif (ipcperms(ns, &sma->sem_perm, S_IWUGO))\n-\t\tgoto out_unlock;\n+\trcu_read_lock();\n+\tsma = sem_obtain_object_check(ns, semid);\n+\tif (IS_ERR(sma)) {\n+\t\trcu_read_unlock();\n+\t\treturn PTR_ERR(sma);\n+\t}\n+\n+\tif (semnum < 0 || semnum >= sma->sem_nsems) {\n+\t\trcu_read_unlock();\n+\t\treturn -EINVAL;\n+\t}\n+\n+\n+\tif (ipcperms(ns, &sma->sem_perm, S_IWUGO)) {\n+\t\trcu_read_unlock();\n+\t\treturn -EACCES;\n+\t}\n \n \terr = security_sem_semctl(sma, SETVAL);\n-\tif (err)\n-\t\tgoto out_unlock;\n+\tif (err) {\n+\t\trcu_read_unlock();\n+\t\treturn -EACCES;\n+\t}\n \n-\terr = -EINVAL;\n-\tif(semnum < 0 || semnum >= nsems)\n-\t\tgoto out_unlock;\n+\tsem_lock(sma, NULL, -1);\n \n \tcurr = &sma->sem_base[semnum];\n \n-\terr = -ERANGE;\n-\tif (val > SEMVMX || val < 0)\n-\t\tgoto out_unlock;\n-\n \tassert_spin_locked(&sma->sem_perm.lock);\n \tlist_for_each_entry(un, &sma->list_id, list_id)\n \t\tun->semadj[semnum] = 0;\n@@ -992,11 +1070,9 @@ static int semctl_setval(struct ipc_namespace *ns, int semid, int semnum,\n \tsma->sem_ctime = get_seconds();\n \t/* maybe some queued-up processes were waiting for this */\n \tdo_smart_update(sma, NULL, 0, 0, &tasks);\n-\terr = 0;\n-out_unlock:\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, -1);\n \twake_up_sem_queue_do(&tasks);\n-\treturn err;\n+\treturn 0;\n }\n \n static int semctl_main(struct ipc_namespace *ns, int semid, int semnum,\n@@ -1051,16 +1127,16 @@ static int semctl_main(struct ipc_namespace *ns, int semid, int semnum,\n \n \t\t\tsem_lock_and_putref(sma);\n \t\t\tif (sma->sem_perm.deleted) {\n-\t\t\t\tsem_unlock(sma);\n+\t\t\t\tsem_unlock(sma, -1);\n \t\t\t\terr = -EIDRM;\n \t\t\t\tgoto out_free;\n \t\t\t}\n-\t\t}\n+\t\t} else\n+\t\t\tsem_lock(sma, NULL, -1);\n \n-\t\tspin_lock(&sma->sem_perm.lock);\n \t\tfor (i = 0; i < sma->sem_nsems; i++)\n \t\t\tsem_io[i] = sma->sem_base[i].semval;\n-\t\tsem_unlock(sma);\n+\t\tsem_unlock(sma, -1);\n \t\terr = 0;\n \t\tif(copy_to_user(array, sem_io, nsems*sizeof(ushort)))\n \t\t\terr = -EFAULT;\n@@ -1071,7 +1147,10 @@ static int semctl_main(struct ipc_namespace *ns, int semid, int semnum,\n \t\tint i;\n \t\tstruct sem_undo *un;\n \n-\t\tipc_rcu_getref(sma);\n+\t\tif (!ipc_rcu_getref(sma)) {\n+\t\t\trcu_read_unlock();\n+\t\t\treturn -EIDRM;\n+\t\t}\n \t\trcu_read_unlock();\n \n \t\tif(nsems > SEMMSL_FAST) {\n@@ -1097,7 +1176,7 @@ static int semctl_main(struct ipc_namespace *ns, int semid, int semnum,\n \t\t}\n \t\tsem_lock_and_putref(sma);\n \t\tif (sma->sem_perm.deleted) {\n-\t\t\tsem_unlock(sma);\n+\t\t\tsem_unlock(sma, -1);\n \t\t\terr = -EIDRM;\n \t\t\tgoto out_free;\n \t\t}\n@@ -1124,7 +1203,7 @@ static int semctl_main(struct ipc_namespace *ns, int semid, int semnum,\n \t\tgoto out_wakeup;\n \t}\n \n-\tspin_lock(&sma->sem_perm.lock);\n+\tsem_lock(sma, NULL, -1);\n \tcurr = &sma->sem_base[semnum];\n \n \tswitch (cmd) {\n@@ -1143,7 +1222,7 @@ static int semctl_main(struct ipc_namespace *ns, int semid, int semnum,\n \t}\n \n out_unlock:\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, -1);\n out_wakeup:\n \twake_up_sem_queue_do(&tasks);\n out_free:\n@@ -1211,11 +1290,11 @@ static int semctl_down(struct ipc_namespace *ns, int semid,\n \n \tswitch(cmd){\n \tcase IPC_RMID:\n-\t\tipc_lock_object(&sma->sem_perm);\n+\t\tsem_lock(sma, NULL, -1);\n \t\tfreeary(ns, ipcp);\n \t\tgoto out_up;\n \tcase IPC_SET:\n-\t\tipc_lock_object(&sma->sem_perm);\n+\t\tsem_lock(sma, NULL, -1);\n \t\terr = ipc_update_perm(&semid64.sem_perm, ipcp);\n \t\tif (err)\n \t\t\tgoto out_unlock;\n@@ -1228,7 +1307,7 @@ static int semctl_down(struct ipc_namespace *ns, int semid,\n \t}\n \n out_unlock:\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, -1);\n out_up:\n \tup_write(&sem_ids(ns).rw_mutex);\n \treturn err;\n@@ -1340,8 +1419,7 @@ static struct sem_undo *find_alloc_undo(struct ipc_namespace *ns, int semid)\n \tstruct sem_array *sma;\n \tstruct sem_undo_list *ulp;\n \tstruct sem_undo *un, *new;\n-\tint nsems;\n-\tint error;\n+\tint nsems, error;\n \n \terror = get_undo_list(&ulp);\n \tif (error)\n@@ -1363,7 +1441,11 @@ static struct sem_undo *find_alloc_undo(struct ipc_namespace *ns, int semid)\n \t}\n \n \tnsems = sma->sem_nsems;\n-\tipc_rcu_getref(sma);\n+\tif (!ipc_rcu_getref(sma)) {\n+\t\trcu_read_unlock();\n+\t\tun = ERR_PTR(-EIDRM);\n+\t\tgoto out;\n+\t}\n \trcu_read_unlock();\n \n \t/* step 2: allocate new undo structure */\n@@ -1376,7 +1458,7 @@ static struct sem_undo *find_alloc_undo(struct ipc_namespace *ns, int semid)\n \t/* step 3: Acquire the lock on semaphore array */\n \tsem_lock_and_putref(sma);\n \tif (sma->sem_perm.deleted) {\n-\t\tsem_unlock(sma);\n+\t\tsem_unlock(sma, -1);\n \t\tkfree(new);\n \t\tun = ERR_PTR(-EIDRM);\n \t\tgoto out;\n@@ -1404,7 +1486,7 @@ static struct sem_undo *find_alloc_undo(struct ipc_namespace *ns, int semid)\n success:\n \tspin_unlock(&ulp->lock);\n \trcu_read_lock();\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, -1);\n out:\n \treturn un;\n }\n@@ -1444,7 +1526,7 @@ SYSCALL_DEFINE4(semtimedop, int, semid, struct sembuf __user *, tsops,\n \tstruct sembuf fast_sops[SEMOPM_FAST];\n \tstruct sembuf* sops = fast_sops, *sop;\n \tstruct sem_undo *un;\n-\tint undos = 0, alter = 0, max;\n+\tint undos = 0, alter = 0, max, locknum;\n \tstruct sem_queue queue;\n \tunsigned long jiffies_left = 0;\n \tstruct ipc_namespace *ns;\n@@ -1488,22 +1570,23 @@ SYSCALL_DEFINE4(semtimedop, int, semid, struct sembuf __user *, tsops,\n \t\t\talter = 1;\n \t}\n \n+\tINIT_LIST_HEAD(&tasks);\n+\n \tif (undos) {\n+\t\t/* On success, find_alloc_undo takes the rcu_read_lock */\n \t\tun = find_alloc_undo(ns, semid);\n \t\tif (IS_ERR(un)) {\n \t\t\terror = PTR_ERR(un);\n \t\t\tgoto out_free;\n \t\t}\n-\t} else\n+\t} else {\n \t\tun = NULL;\n+\t\trcu_read_lock();\n+\t}\n \n-\tINIT_LIST_HEAD(&tasks);\n-\n-\trcu_read_lock();\n \tsma = sem_obtain_object_check(ns, semid);\n \tif (IS_ERR(sma)) {\n-\t\tif (un)\n-\t\t\trcu_read_unlock();\n+\t\trcu_read_unlock();\n \t\terror = PTR_ERR(sma);\n \t\tgoto out_free;\n \t}\n@@ -1534,23 +1617,9 @@ SYSCALL_DEFINE4(semtimedop, int, semid, struct sembuf __user *, tsops,\n \t * \"un\" itself is guaranteed by rcu.\n \t */\n \terror = -EIDRM;\n-\tipc_lock_object(&sma->sem_perm);\n-\tif (un) {\n-\t\tif (un->semid == -1) {\n-\t\t\trcu_read_unlock();\n-\t\t\tgoto out_unlock_free;\n-\t\t} else {\n-\t\t\t/*\n-\t\t\t * rcu lock can be released, \"un\" cannot disappear:\n-\t\t\t * - sem_lock is acquired, thus IPC_RMID is\n-\t\t\t *   impossible.\n-\t\t\t * - exit_sem is impossible, it always operates on\n-\t\t\t *   current (or a dead task).\n-\t\t\t */\n-\n-\t\t\trcu_read_unlock();\n-\t\t}\n-\t}\n+\tlocknum = sem_lock(sma, sops, nsops);\n+\tif (un && un->semid == -1)\n+\t\tgoto out_unlock_free;\n \n \terror = try_atomic_semop (sma, sops, nsops, un, task_tgid_vnr(current));\n \tif (error <= 0) {\n@@ -1591,7 +1660,7 @@ SYSCALL_DEFINE4(semtimedop, int, semid, struct sembuf __user *, tsops,\n \n sleep_again:\n \tcurrent->state = TASK_INTERRUPTIBLE;\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, locknum);\n \n \tif (timeout)\n \t\tjiffies_left = schedule_timeout(jiffies_left);\n@@ -1613,7 +1682,7 @@ SYSCALL_DEFINE4(semtimedop, int, semid, struct sembuf __user *, tsops,\n \t\tgoto out_free;\n \t}\n \n-\tsma = sem_obtain_lock(ns, semid);\n+\tsma = sem_obtain_lock(ns, semid, sops, nsops, &locknum);\n \n \t/*\n \t * Wait until it's guaranteed that no wakeup_sem_queue_do() is ongoing.\n@@ -1652,7 +1721,7 @@ SYSCALL_DEFINE4(semtimedop, int, semid, struct sembuf __user *, tsops,\n \tunlink_queue(sma, &queue);\n \n out_unlock_free:\n-\tsem_unlock(sma);\n+\tsem_unlock(sma, locknum);\n out_wakeup:\n \twake_up_sem_queue_do(&tasks);\n out_free:\n@@ -1716,8 +1785,7 @@ void exit_sem(struct task_struct *tsk)\n \t\tstruct sem_array *sma;\n \t\tstruct sem_undo *un;\n \t\tstruct list_head tasks;\n-\t\tint semid;\n-\t\tint i;\n+\t\tint semid, i;\n \n \t\trcu_read_lock();\n \t\tun = list_entry_rcu(ulp->list_proc.next,\n@@ -1726,23 +1794,26 @@ void exit_sem(struct task_struct *tsk)\n \t\t\tsemid = -1;\n \t\t else\n \t\t\tsemid = un->semid;\n-\t\trcu_read_unlock();\n \n-\t\tif (semid == -1)\n+\t\tif (semid == -1) {\n+\t\t\trcu_read_unlock();\n \t\t\tbreak;\n+\t\t}\n \n-\t\tsma = sem_lock_check(tsk->nsproxy->ipc_ns, un->semid);\n-\n+\t\tsma = sem_obtain_object_check(tsk->nsproxy->ipc_ns, un->semid);\n \t\t/* exit_sem raced with IPC_RMID, nothing to do */\n-\t\tif (IS_ERR(sma))\n+\t\tif (IS_ERR(sma)) {\n+\t\t\trcu_read_unlock();\n \t\t\tcontinue;\n+\t\t}\n \n+\t\tsem_lock(sma, NULL, -1);\n \t\tun = __lookup_undo(ulp, semid);\n \t\tif (un == NULL) {\n \t\t\t/* exit_sem raced with IPC_RMID+semget() that created\n \t\t\t * exactly the same semid. Nothing to do.\n \t\t\t */\n-\t\t\tsem_unlock(sma);\n+\t\t\tsem_unlock(sma, -1);\n \t\t\tcontinue;\n \t\t}\n \n@@ -1782,7 +1853,7 @@ void exit_sem(struct task_struct *tsk)\n \t\t/* maybe some queued-up processes were waiting for this */\n \t\tINIT_LIST_HEAD(&tasks);\n \t\tdo_smart_update(sma, NULL, 0, 1, &tasks);\n-\t\tsem_unlock(sma);\n+\t\tsem_unlock(sma, -1);\n \t\twake_up_sem_queue_do(&tasks);\n \n \t\tkfree_rcu(un, rcu);\n",
    "fix_code": "static inline struct sem_array *sem_obtain_lock(struct ipc_namespace *ns,\n\t\t\tint id, struct sembuf *sops, int nsops, int *locknum)\n{\n\tstruct kern_ipc_perm *ipcp;\n\tstruct sem_array *sma;\n\n\trcu_read_lock();\n\tipcp = ipc_obtain_object(&sem_ids(ns), id);\n\tif (IS_ERR(ipcp)) {\n\t\tsma = ERR_CAST(ipcp);\n\t\tgoto err;\n\t}\n\n\tsma = container_of(ipcp, struct sem_array, sem_perm);\n\t*locknum = sem_lock(sma, sops, nsops);\n\n\t/* ipc_rmid() may have already freed the ID while sem_lock\n\t * was spinning: verify that the structure is still valid\n\t */\n\tif (!ipcp->deleted)\n\t\treturn container_of(ipcp, struct sem_array, sem_perm);\n\n\tsem_unlock(sma, *locknum);\n\tsma = ERR_PTR(-EINVAL);\nerr:\n\trcu_read_unlock();\n\treturn sma;\n}"
  }]